{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11316866,"sourceType":"datasetVersion","datasetId":7078734},{"sourceId":327567,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":274918,"modelId":295806}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# IMPORT","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%capture\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchaudio\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch.optim as optim\nfrom torch.nn import CTCLoss\nfrom torchinfo import summary\n\nimport time\nfrom datetime import datetime\nfrom tqdm import tqdm\n\nfrom tokenizers import Tokenizer\nfrom tokenizers.models import WordPiece\nfrom tokenizers.trainers import WordPieceTrainer\nfrom tokenizers.pre_tokenizers import Whitespace\n\nfrom sklearn.model_selection import train_test_split\n\nimport typing as tp\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:21:26.157691Z","iopub.execute_input":"2025-04-09T11:21:26.158067Z","iopub.status.idle":"2025-04-09T11:23:10.306855Z","shell.execute_reply.started":"2025-04-09T11:21:26.158040Z","shell.execute_reply":"2025-04-09T11:23:10.305890Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# PATH","metadata":{}},{"cell_type":"code","source":"DATA_DIR = '/kaggle/input/english-single-word-dataset/en'\n\nSAVE_DIR_1000 = '/kaggle/working/data/1000words'\n\nSAVE_DIR_5000 = '/kaggle/working/data/5000words'\n\nSAVE_DIR_ALL = '/kaggle/working/data/all'\n\nMODEL_1_DIR = '/kaggle/working/models/model1'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:23:10.308034Z","iopub.execute_input":"2025-04-09T11:23:10.308553Z","iopub.status.idle":"2025-04-09T11:23:10.312358Z","shell.execute_reply.started":"2025-04-09T11:23:10.308521Z","shell.execute_reply":"2025-04-09T11:23:10.311491Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"TARGET_DIR = SAVE_DIR_ALL\n\nos.makedirs(TARGET_DIR, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:23:10.313857Z","iopub.execute_input":"2025-04-09T11:23:10.314073Z","iopub.status.idle":"2025-04-09T11:23:10.326861Z","shell.execute_reply.started":"2025-04-09T11:23:10.314054Z","shell.execute_reply":"2025-04-09T11:23:10.325945Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# SAVE","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:23:10.327958Z","iopub.execute_input":"2025-04-09T11:23:10.328161Z","iopub.status.idle":"2025-04-09T11:23:10.391256Z","shell.execute_reply.started":"2025-04-09T11:23:10.328143Z","shell.execute_reply":"2025-04-09T11:23:10.390610Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# dataframes versions control\ndef save_dataframe(file_name_ext: str, df: pd.DataFrame, directory: str = TARGET_DIR):\n\n    # file format define and checking\n    fex_splitted = file_name_ext.split('.')\n    file_name = fex_splitted[0]\n    file_extension = fex_splitted[1]\n    assert file_extension in ['parquet', 'csv', 'xlsx'], 'FILE FORMAT NOT ACCEPTING!!!'\n\n    # ensure directory and file path existence\n    path = os.path.join(directory, file_name)\n    os.makedirs(directory, exist_ok=True)\n    os.makedirs(path, exist_ok=True)\n\n    # filter out target filename\n    files_version = [file.split('_')[-1] for file in os.listdir(path) if file.split('_')[0] == file_name]\n\n    # find the latest file version\n    file_version = 'v1'\n    if files_version:\n        version_str = max(files_version).split('.')[0]\n        file_version = ''.join([str(int(c)+1) if idx == 1 else c for idx, c in enumerate(list(version_str))])\n\n    # define file path\n    file_name_ext_2 = file_name + '_' + file_version + '.' + file_extension\n    file_path = os.path.join(path, file_name_ext_2)\n\n    # save file\n    if file_extension == 'parquet':\n        df.to_parquet(file_path, index=False)\n    elif file_extension == 'csv':\n        df.to_csv(file_path, index=False)\n    elif file_extension == 'xlsx':\n        df.to_excel(file_path, index=False)\n\n    print(f'dataframe saved at \"{file_path}\" in {file_extension} format')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:23:10.392129Z","iopub.execute_input":"2025-04-09T11:23:10.392419Z","iopub.status.idle":"2025-04-09T11:23:10.410945Z","shell.execute_reply.started":"2025-04-09T11:23:10.392389Z","shell.execute_reply":"2025-04-09T11:23:10.410325Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\"\"\"save_dataframe('test.csv', pd.DataFrame({\n    'test': ['apple']\n}), SAVE_DIR_5000)\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:23:10.411563Z","iopub.execute_input":"2025-04-09T11:23:10.411790Z","iopub.status.idle":"2025-04-09T11:23:10.427940Z","shell.execute_reply.started":"2025-04-09T11:23:10.411771Z","shell.execute_reply":"2025-04-09T11:23:10.427297Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"\"save_dataframe('test.csv', pd.DataFrame({\\n    'test': ['apple']\\n}), SAVE_DIR_5000)\""},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# IMPORT","metadata":{}},{"cell_type":"code","source":"def import_tsv(file_name_ext: str, directory: str = DATA_DIR):\n\n    file_path = os.path.join(directory, file_name_ext)\n    df = pd.read_csv(file_path, sep='\\t')\n\n    print(f'import data shape: {df.shape}')\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:23:10.428574Z","iopub.execute_input":"2025-04-09T11:23:10.428787Z","iopub.status.idle":"2025-04-09T11:23:10.442875Z","shell.execute_reply.started":"2025-04-09T11:23:10.428769Z","shell.execute_reply":"2025-04-09T11:23:10.442113Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import_df = import_tsv('train.tsv')\n\nimport_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:23:10.445331Z","iopub.execute_input":"2025-04-09T11:23:10.445557Z","iopub.status.idle":"2025-04-09T11:23:10.566627Z","shell.execute_reply.started":"2025-04-09T11:23:10.445538Z","shell.execute_reply":"2025-04-09T11:23:10.565774Z"}},"outputs":[{"name":"stdout","text":"import data shape: (16285, 10)\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                           client_id  \\\n0  1476c13940c901d1a5a10630c6d84205d0780be5beec08...   \n1  1476c13940c901d1a5a10630c6d84205d0780be5beec08...   \n2  1476c13940c901d1a5a10630c6d84205d0780be5beec08...   \n3  1476c13940c901d1a5a10630c6d84205d0780be5beec08...   \n4  1476c13940c901d1a5a10630c6d84205d0780be5beec08...   \n\n                           path sentence  up_votes  down_votes       age  \\\n0  common_voice_en_22107292.mp3  Firefox         2           0  twenties   \n1  common_voice_en_22107294.mp3    eight         2           0  twenties   \n2  common_voice_en_22107295.mp3      Hey         3           0  twenties   \n3  common_voice_en_22107296.mp3      yes         2           0  twenties   \n4  common_voice_en_22107308.mp3     five         2           1  twenties   \n\n  gender  accent locale    segment  \n0   male  indian     en  Benchmark  \n1   male  indian     en  Benchmark  \n2   male  indian     en  Benchmark  \n3   male  indian     en  Benchmark  \n4   male  indian     en  Benchmark  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>client_id</th>\n      <th>path</th>\n      <th>sentence</th>\n      <th>up_votes</th>\n      <th>down_votes</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>accent</th>\n      <th>locale</th>\n      <th>segment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1476c13940c901d1a5a10630c6d84205d0780be5beec08...</td>\n      <td>common_voice_en_22107292.mp3</td>\n      <td>Firefox</td>\n      <td>2</td>\n      <td>0</td>\n      <td>twenties</td>\n      <td>male</td>\n      <td>indian</td>\n      <td>en</td>\n      <td>Benchmark</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1476c13940c901d1a5a10630c6d84205d0780be5beec08...</td>\n      <td>common_voice_en_22107294.mp3</td>\n      <td>eight</td>\n      <td>2</td>\n      <td>0</td>\n      <td>twenties</td>\n      <td>male</td>\n      <td>indian</td>\n      <td>en</td>\n      <td>Benchmark</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1476c13940c901d1a5a10630c6d84205d0780be5beec08...</td>\n      <td>common_voice_en_22107295.mp3</td>\n      <td>Hey</td>\n      <td>3</td>\n      <td>0</td>\n      <td>twenties</td>\n      <td>male</td>\n      <td>indian</td>\n      <td>en</td>\n      <td>Benchmark</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1476c13940c901d1a5a10630c6d84205d0780be5beec08...</td>\n      <td>common_voice_en_22107296.mp3</td>\n      <td>yes</td>\n      <td>2</td>\n      <td>0</td>\n      <td>twenties</td>\n      <td>male</td>\n      <td>indian</td>\n      <td>en</td>\n      <td>Benchmark</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1476c13940c901d1a5a10630c6d84205d0780be5beec08...</td>\n      <td>common_voice_en_22107308.mp3</td>\n      <td>five</td>\n      <td>2</td>\n      <td>1</td>\n      <td>twenties</td>\n      <td>male</td>\n      <td>indian</td>\n      <td>en</td>\n      <td>Benchmark</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"# PREPROCESS","metadata":{}},{"cell_type":"markdown","source":"## col","metadata":{}},{"cell_type":"code","source":"col_df = import_df[['path', 'sentence']]\n\ncol_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:23:10.568100Z","iopub.execute_input":"2025-04-09T11:23:10.568328Z","iopub.status.idle":"2025-04-09T11:23:10.582569Z","shell.execute_reply.started":"2025-04-09T11:23:10.568308Z","shell.execute_reply":"2025-04-09T11:23:10.581915Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                           path sentence\n0  common_voice_en_22107292.mp3  Firefox\n1  common_voice_en_22107294.mp3    eight\n2  common_voice_en_22107295.mp3      Hey\n3  common_voice_en_22107296.mp3      yes\n4  common_voice_en_22107308.mp3     five","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>common_voice_en_22107292.mp3</td>\n      <td>Firefox</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>common_voice_en_22107294.mp3</td>\n      <td>eight</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>common_voice_en_22107295.mp3</td>\n      <td>Hey</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>common_voice_en_22107296.mp3</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>common_voice_en_22107308.mp3</td>\n      <td>five</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"col_df_2 = col_df.copy()\n\ncol_df_2['path'] = col_df_2['path'].apply(lambda x: os.path.join(DATA_DIR, 'clips', x))\ncol_df_2['sentence'] = col_df_2['sentence'].apply(lambda x: str(x).lower().strip())\n\ncol_df_2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:23:10.583446Z","iopub.execute_input":"2025-04-09T11:23:10.583706Z","iopub.status.idle":"2025-04-09T11:23:10.627537Z","shell.execute_reply.started":"2025-04-09T11:23:10.583662Z","shell.execute_reply":"2025-04-09T11:23:10.626866Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                                    path sentence\n0      /kaggle/input/english-single-word-dataset/en/c...  firefox\n1      /kaggle/input/english-single-word-dataset/en/c...    eight\n2      /kaggle/input/english-single-word-dataset/en/c...      hey\n3      /kaggle/input/english-single-word-dataset/en/c...      yes\n4      /kaggle/input/english-single-word-dataset/en/c...     five\n...                                                  ...      ...\n16280  /kaggle/input/english-single-word-dataset/en/c...     four\n16281  /kaggle/input/english-single-word-dataset/en/c...       no\n16282  /kaggle/input/english-single-word-dataset/en/c...      one\n16283  /kaggle/input/english-single-word-dataset/en/c...      yes\n16284  /kaggle/input/english-single-word-dataset/en/c...      six\n\n[16285 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>firefox</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>eight</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>hey</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>five</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16280</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>four</td>\n    </tr>\n    <tr>\n      <th>16281</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>16282</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>one</td>\n    </tr>\n    <tr>\n      <th>16283</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>16284</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>six</td>\n    </tr>\n  </tbody>\n</table>\n<p>16285 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"\"\"\"save_dataframe('col_df_2.parquet', col_df_2)\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:23:10.628367Z","iopub.execute_input":"2025-04-09T11:23:10.628573Z","iopub.status.idle":"2025-04-09T11:23:10.645207Z","shell.execute_reply.started":"2025-04-09T11:23:10.628555Z","shell.execute_reply":"2025-04-09T11:23:10.644531Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"\"save_dataframe('col_df_2.parquet', col_df_2)\""},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"## row","metadata":{}},{"cell_type":"code","source":"row_df = col_df_2.copy()\n\nrow_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:23:10.646027Z","iopub.execute_input":"2025-04-09T11:23:10.646302Z","iopub.status.idle":"2025-04-09T11:23:10.665490Z","shell.execute_reply.started":"2025-04-09T11:23:10.646281Z","shell.execute_reply":"2025-04-09T11:23:10.664636Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                                    path sentence\n0      /kaggle/input/english-single-word-dataset/en/c...  firefox\n1      /kaggle/input/english-single-word-dataset/en/c...    eight\n2      /kaggle/input/english-single-word-dataset/en/c...      hey\n3      /kaggle/input/english-single-word-dataset/en/c...      yes\n4      /kaggle/input/english-single-word-dataset/en/c...     five\n...                                                  ...      ...\n16280  /kaggle/input/english-single-word-dataset/en/c...     four\n16281  /kaggle/input/english-single-word-dataset/en/c...       no\n16282  /kaggle/input/english-single-word-dataset/en/c...      one\n16283  /kaggle/input/english-single-word-dataset/en/c...      yes\n16284  /kaggle/input/english-single-word-dataset/en/c...      six\n\n[16285 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>firefox</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>eight</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>hey</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>five</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16280</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>four</td>\n    </tr>\n    <tr>\n      <th>16281</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>16282</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>one</td>\n    </tr>\n    <tr>\n      <th>16283</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>16284</th>\n      <td>/kaggle/input/english-single-word-dataset/en/c...</td>\n      <td>six</td>\n    </tr>\n  </tbody>\n</table>\n<p>16285 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"\"\"\"save_dataframe('row_df.parquet', row_df)\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:23:10.666458Z","iopub.execute_input":"2025-04-09T11:23:10.666817Z","iopub.status.idle":"2025-04-09T11:23:10.671216Z","shell.execute_reply.started":"2025-04-09T11:23:10.666785Z","shell.execute_reply":"2025-04-09T11:23:10.670563Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"\"save_dataframe('row_df.parquet', row_df)\""},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"## audio","metadata":{}},{"cell_type":"code","source":"def convert_mp3_audio(df: pd.DataFrame, target_sr: int = 16_000) -> pd.DataFrame:\n\n    samples = []\n    samples_length = []\n    s_rates = []\n\n    for f_path in tqdm(df['path'], desc='Processing Audio Files'):\n\n        wv, sr = torchaudio.load(f_path)\n\n        if sr != target_sr:\n            transform = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sr)\n            wv = transform(wv)\n\n        wv_np = np.array(wv.squeeze(0))\n\n        samples.append(wv_np)\n        samples_length.append(wv.shape[1])\n        s_rates.append(target_sr)\n\n    \n    print(f'audios mp3 converted into audios arrays')\n    return samples, samples_length, s_rates","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:23:10.671867Z","iopub.execute_input":"2025-04-09T11:23:10.672043Z","iopub.status.idle":"2025-04-09T11:23:10.685692Z","shell.execute_reply.started":"2025-04-09T11:23:10.672026Z","shell.execute_reply":"2025-04-09T11:23:10.684925Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"%%capture\nsamples, samples_length, s_rates = convert_mp3_audio(row_df)\n\nsamples, samples_length, s_rates","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:23:10.686478Z","iopub.execute_input":"2025-04-09T11:23:10.686719Z","iopub.status.idle":"2025-04-09T11:26:18.463600Z","shell.execute_reply.started":"2025-04-09T11:23:10.686689Z","shell.execute_reply":"2025-04-09T11:26:18.462684Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"mp3toArray_df = pd.DataFrame({\n       'sample': samples,\n       'sample_length': samples_length,\n       's_rate': s_rates,\n       'sentence': row_df['sentence']\n   })\n\nmp3toArray_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:26:18.464490Z","iopub.execute_input":"2025-04-09T11:26:18.464821Z","iopub.status.idle":"2025-04-09T11:26:18.492414Z","shell.execute_reply.started":"2025-04-09T11:26:18.464790Z","shell.execute_reply":"2025-04-09T11:26:18.491733Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                                  sample  sample_length  \\\n0      [-4.470679e-15, 2.2563098e-15, -2.7510187e-14,...          64128   \n1      [-6.826243e-14, -1.3892575e-13, -3.2341327e-15...          56832   \n2      [1.2781484e-14, -6.065027e-15, -4.3284217e-14,...          47232   \n3      [2.2558176e-14, 7.1377156e-14, 1.2601685e-13, ...          59520   \n4      [1.076456e-14, 3.442678e-14, 4.160499e-14, 6.1...          39168   \n...                                                  ...            ...   \n16280  [2.5066728e-16, 7.378162e-16, 5.588148e-16, 5....          33408   \n16281  [-6.589155e-15, 2.1930186e-14, -1.0722097e-15,...          35328   \n16282  [1.3627174e-14, -3.7066182e-14, 5.142285e-15, ...          31104   \n16283  [-3.3386209e-16, 1.3234546e-16, -1.7972e-15, -...          31872   \n16284  [-2.021378e-15, -4.125126e-16, 3.1908498e-15, ...          33408   \n\n       s_rate sentence  \n0       16000  firefox  \n1       16000    eight  \n2       16000      hey  \n3       16000      yes  \n4       16000     five  \n...       ...      ...  \n16280   16000     four  \n16281   16000       no  \n16282   16000      one  \n16283   16000      yes  \n16284   16000      six  \n\n[16285 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample</th>\n      <th>sample_length</th>\n      <th>s_rate</th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[-4.470679e-15, 2.2563098e-15, -2.7510187e-14,...</td>\n      <td>64128</td>\n      <td>16000</td>\n      <td>firefox</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[-6.826243e-14, -1.3892575e-13, -3.2341327e-15...</td>\n      <td>56832</td>\n      <td>16000</td>\n      <td>eight</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[1.2781484e-14, -6.065027e-15, -4.3284217e-14,...</td>\n      <td>47232</td>\n      <td>16000</td>\n      <td>hey</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[2.2558176e-14, 7.1377156e-14, 1.2601685e-13, ...</td>\n      <td>59520</td>\n      <td>16000</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[1.076456e-14, 3.442678e-14, 4.160499e-14, 6.1...</td>\n      <td>39168</td>\n      <td>16000</td>\n      <td>five</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16280</th>\n      <td>[2.5066728e-16, 7.378162e-16, 5.588148e-16, 5....</td>\n      <td>33408</td>\n      <td>16000</td>\n      <td>four</td>\n    </tr>\n    <tr>\n      <th>16281</th>\n      <td>[-6.589155e-15, 2.1930186e-14, -1.0722097e-15,...</td>\n      <td>35328</td>\n      <td>16000</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>16282</th>\n      <td>[1.3627174e-14, -3.7066182e-14, 5.142285e-15, ...</td>\n      <td>31104</td>\n      <td>16000</td>\n      <td>one</td>\n    </tr>\n    <tr>\n      <th>16283</th>\n      <td>[-3.3386209e-16, 1.3234546e-16, -1.7972e-15, -...</td>\n      <td>31872</td>\n      <td>16000</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>16284</th>\n      <td>[-2.021378e-15, -4.125126e-16, 3.1908498e-15, ...</td>\n      <td>33408</td>\n      <td>16000</td>\n      <td>six</td>\n    </tr>\n  </tbody>\n</table>\n<p>16285 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"save_dataframe('mp3toArray_df.parquet', mp3toArray_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:26:18.493194Z","iopub.execute_input":"2025-04-09T11:26:18.493445Z","iopub.status.idle":"2025-04-09T11:26:48.133535Z","shell.execute_reply.started":"2025-04-09T11:26:18.493423Z","shell.execute_reply":"2025-04-09T11:26:48.132786Z"}},"outputs":[{"name":"stdout","text":"dataframe saved at \"/kaggle/working/data/all/mp3toArray_df/mp3toArray_df_v1.parquet\" in parquet format\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# PROCESS","metadata":{}},{"cell_type":"code","source":"\"\"\"mp3toArray_df = pd.read_parquet('/kaggle/working/data/5000words/mp3toArray_df/mp3toArray_df_v1.parquet')\n\nmp3toArray_df\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:26:48.134522Z","iopub.execute_input":"2025-04-09T11:26:48.134808Z","iopub.status.idle":"2025-04-09T11:26:48.139374Z","shell.execute_reply.started":"2025-04-09T11:26:48.134786Z","shell.execute_reply":"2025-04-09T11:26:48.138668Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"\"mp3toArray_df = pd.read_parquet('/kaggle/working/data/5000words/mp3toArray_df/mp3toArray_df_v1.parquet')\\n\\nmp3toArray_df\""},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"## word","metadata":{}},{"cell_type":"code","source":"# get unique words and save\nunique_words = mp3toArray_df['sentence'].unique()\n\ntext_path = os.path.join(TARGET_DIR, 'words.txt')\n\nwith open(text_path, 'w', encoding='utf-8') as f:\n    for word in unique_words:\n        f.write(word + '\\n')\n\nprint(f'vocab saved at {text_path}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:26:48.140074Z","iopub.execute_input":"2025-04-09T11:26:48.140256Z","iopub.status.idle":"2025-04-09T11:26:48.162951Z","shell.execute_reply.started":"2025-04-09T11:26:48.140239Z","shell.execute_reply":"2025-04-09T11:26:48.162069Z"}},"outputs":[{"name":"stdout","text":"vocab saved at /kaggle/working/data/all/words.txt\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"def train_tokenizer(unique_words: list, path: str = TARGET_DIR):\n\n    # ensure path existence\n    tokens_path = os.path.join(path, 'tokenizer_checkpoint.json')\n    \n    # instantiate tokenizer\n    tokenizer = Tokenizer(WordPiece(unk_token='[UNK]'))\n    tokenizer.pre_tokenizer = Whitespace()\n\n    # molde the tokenizer and save\n    special_tokens = ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]']\n    tokenizer.train([text_path], WordPieceTrainer(vocab_size=len(unique_words), min_frequency=1, special_tokens=special_tokens))\n    tokenizer.save(tokens_path)\n\n    print(f'tokenizer checkpoint saved at {tokens_path}')\n    \n    return tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:26:48.163869Z","iopub.execute_input":"2025-04-09T11:26:48.164182Z","iopub.status.idle":"2025-04-09T11:26:48.241428Z","shell.execute_reply.started":"2025-04-09T11:26:48.164149Z","shell.execute_reply":"2025-04-09T11:26:48.240513Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"tokenizer = train_tokenizer(unique_words)\n\ntokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:26:48.242346Z","iopub.execute_input":"2025-04-09T11:26:48.242838Z","iopub.status.idle":"2025-04-09T11:26:57.874997Z","shell.execute_reply.started":"2025-04-09T11:26:48.242806Z","shell.execute_reply":"2025-04-09T11:26:57.874146Z"}},"outputs":[{"name":"stdout","text":"tokenizer checkpoint saved at /kaggle/working/data/all/tokenizer_checkpoint.json\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Tokenizer(version=\"1.0\", truncation=None, padding=None, added_tokens=[{\"id\":0, \"content\":\"[PAD]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":1, \"content\":\"[UNK]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":2, \"content\":\"[CLS]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":3, \"content\":\"[SEP]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":4, \"content\":\"[MASK]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}], normalizer=None, pre_tokenizer=Whitespace(), post_processor=None, decoder=None, model=WordPiece(unk_token=\"[UNK]\", continuing_subword_prefix=\"##\", max_input_chars_per_word=100, vocab={\"[PAD]\":0, \"[UNK]\":1, \"[CLS]\":2, \"[SEP]\":3, \"[MASK]\":4, \"e\":5, \"f\":6, \"g\":7, \"h\":8, \"i\":9, \"n\":10, \"o\":11, \"r\":12, \"s\":13, \"t\":14, \"u\":15, \"v\":16, \"w\":17, \"x\":18, \"y\":19, \"z\":20, \"##e\":21, \"##s\":22, \"##y\":23, \"##w\":24, \"##o\":25, \"##i\":26, \"##n\":27, \"##u\":28, \"##r\":29, \"##v\":30, \"##g\":31, \"##h\":32, \"##t\":33, \"##f\":34, \"##x\":35}))"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"vocab_size= tokenizer.get_vocab()\n\nlen(vocab_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:26:57.875854Z","iopub.execute_input":"2025-04-09T11:26:57.876134Z","iopub.status.idle":"2025-04-09T11:26:57.880877Z","shell.execute_reply.started":"2025-04-09T11:26:57.876101Z","shell.execute_reply":"2025-04-09T11:26:57.880070Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"36"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"def detokenize(token_ids):\n    word = []\n    for item in token_ids.split(' '):\n        if item.startswith('##'):\n            item = item[2:]\n        word.append(item)\n    return ''.join(word)\n\ndetokenize('eu %eu #eu eu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:26:57.885110Z","iopub.execute_input":"2025-04-09T11:26:57.885311Z","iopub.status.idle":"2025-04-09T11:26:57.896989Z","shell.execute_reply.started":"2025-04-09T11:26:57.885294Z","shell.execute_reply":"2025-04-09T11:26:57.896302Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'eu%eu#eueu'"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"%%capture\ntokens = list(mp3toArray_df['sentence'].apply(lambda x: tokenizer.encode(x).ids))\n\ntokens, len(tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:26:57.898851Z","iopub.execute_input":"2025-04-09T11:26:57.899110Z","iopub.status.idle":"2025-04-09T11:26:58.031512Z","shell.execute_reply.started":"2025-04-09T11:26:57.899090Z","shell.execute_reply":"2025-04-09T11:26:58.030752Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"tokens_tensor = [torch.tensor(tok, dtype=torch.long) for tok in tokens]\npad_tokens = pad_sequence(tokens_tensor, batch_first=True, padding_value=0)\n\npad_tokens, len(pad_tokens), len(pad_tokens[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:26:58.032462Z","iopub.execute_input":"2025-04-09T11:26:58.032779Z","iopub.status.idle":"2025-04-09T11:26:58.192815Z","shell.execute_reply.started":"2025-04-09T11:26:58.032749Z","shell.execute_reply":"2025-04-09T11:26:58.192107Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(tensor([[ 6, 26, 29,  ..., 34, 25, 35],\n         [ 5, 26, 31,  ..., 33,  0,  0],\n         [ 8, 21, 23,  ...,  0,  0,  0],\n         ...,\n         [11, 27, 21,  ...,  0,  0,  0],\n         [19, 21, 22,  ...,  0,  0,  0],\n         [13, 26, 35,  ...,  0,  0,  0]]),\n 16285,\n 7)"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"## audio","metadata":{}},{"cell_type":"code","source":"audio_samples = mp3toArray_df['sample']\n\naudio_samples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:26:58.193638Z","iopub.execute_input":"2025-04-09T11:26:58.193959Z","iopub.status.idle":"2025-04-09T11:26:58.203785Z","shell.execute_reply.started":"2025-04-09T11:26:58.193929Z","shell.execute_reply":"2025-04-09T11:26:58.202871Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"0        [-4.470679e-15, 2.2563098e-15, -2.7510187e-14,...\n1        [-6.826243e-14, -1.3892575e-13, -3.2341327e-15...\n2        [1.2781484e-14, -6.065027e-15, -4.3284217e-14,...\n3        [2.2558176e-14, 7.1377156e-14, 1.2601685e-13, ...\n4        [1.076456e-14, 3.442678e-14, 4.160499e-14, 6.1...\n                               ...                        \n16280    [2.5066728e-16, 7.378162e-16, 5.588148e-16, 5....\n16281    [-6.589155e-15, 2.1930186e-14, -1.0722097e-15,...\n16282    [1.3627174e-14, -3.7066182e-14, 5.142285e-15, ...\n16283    [-3.3386209e-16, 1.3234546e-16, -1.7972e-15, -...\n16284    [-2.021378e-15, -4.125126e-16, 3.1908498e-15, ...\nName: sample, Length: 16285, dtype: object"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"def convert_into_mel(samples):\n    transforms = torchaudio.transforms.MelSpectrogram(sample_rate=16_000, n_fft=1024, hop_length=512)\n    mel_samples = [transforms(torch.tensor(sample, dtype=torch.float32)) for sample in samples]\n    print(f'mel sample shape: {mel_samples[-1].shape}')\n    return mel_samples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:26:58.204675Z","iopub.execute_input":"2025-04-09T11:26:58.204984Z","iopub.status.idle":"2025-04-09T11:26:58.218841Z","shell.execute_reply.started":"2025-04-09T11:26:58.204957Z","shell.execute_reply":"2025-04-09T11:26:58.218121Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"%%capture\nmel_samples = list(convert_into_mel(audio_samples))\n\nmel_samples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:26:58.219517Z","iopub.execute_input":"2025-04-09T11:26:58.219778Z","iopub.status.idle":"2025-04-09T11:27:10.469769Z","shell.execute_reply.started":"2025-04-09T11:26:58.219737Z","shell.execute_reply":"2025-04-09T11:27:10.469040Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"# SPLIT","metadata":{}},{"cell_type":"code","source":"len(mel_samples), len(tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:10.470505Z","iopub.execute_input":"2025-04-09T11:27:10.470749Z","iopub.status.idle":"2025-04-09T11:27:10.475492Z","shell.execute_reply.started":"2025-04-09T11:27:10.470727Z","shell.execute_reply":"2025-04-09T11:27:10.474757Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"(16285, 16285)"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(mel_samples, tokens_tensor, test_size=0.2, random_state=42, shuffle=True)\n\nprint(f'training size (x, y) -> {len(X_train), len(y_train)}')\nprint(f'and test size (x, y) -> {len(X_test), len(y_test)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:10.476244Z","iopub.execute_input":"2025-04-09T11:27:10.476537Z","iopub.status.idle":"2025-04-09T11:27:10.502834Z","shell.execute_reply.started":"2025-04-09T11:27:10.476505Z","shell.execute_reply":"2025-04-09T11:27:10.502048Z"}},"outputs":[{"name":"stdout","text":"training size (x, y) -> (13028, 13028)\nand test size (x, y) -> (3257, 3257)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"# LOADER","metadata":{}},{"cell_type":"code","source":"# getting data max length for loading into batches with padding\naudio_max_length = max([mel.shape[1] for mel in mel_samples])\n\naudio_max_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:10.503705Z","iopub.execute_input":"2025-04-09T11:27:10.503945Z","iopub.status.idle":"2025-04-09T11:27:10.529484Z","shell.execute_reply.started":"2025-04-09T11:27:10.503926Z","shell.execute_reply":"2025-04-09T11:27:10.528828Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"361"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"# mel_tensors: (C, T)\n# knowing that audios array have 1000 units, so we can batch perfectly into test_batches of 4, also because of \n# my notebook only has 6gb of gpu ram so i can only run this little test_batches per time, \n# setting audio max len to 298 to add natural silence into missing parts, plus we got 128 of mel frequency bins by cepstral by default\ndef mel_loader_2(\n        mel_tensors: tp.List[torch.tensor], token_ids: list, \n        batch_size: int = 4, mel_freq_bins: int = 128, mel_time_step: tp.Optional[int] = None\n        ):\n    \"\"\"\n        Custom Data Loader for Mel Spectrogram\n    \"\"\"\n    assert all([mel.shape[0] == 128 for mel in mel_tensors]), 'MEL FREQUENCY NOT MATCHING!!!' # ensure that we got the right data size\n\n    # calculating total batches number\n    all_len = len(mel_tensors)\n    batches_len = all_len//batch_size\n\n    original_mel_lengths = [mel.shape[1] for mel in mel_tensors]\n    if mel_time_step is None:\n        mel_time_step = max(original_mel_lengths)\n        print(f\"[INFO] Auto-set mel_time_step to max found: {mel_time_step}\")\n    \n    # explicitly padding mel tensors (just adding missing parts then concat it)\n    mels_padded = torch.stack([\n        torch.concat([mel, torch.zeros(mel_freq_bins, mel_time_step-mel.shape[1])], dim=1)\n        if mel.shape[1] < mel_time_step else mel[:, :mel_time_step]\n        for mel in mel_tensors\n    ])\n\n    # returning padded mels and token_ids but formatted into desired sizes\n    mels_padded = mels_padded[:batches_len * batch_size]  # trim any overflow\n    batches_audio = mels_padded.view(batches_len, batch_size, mel_freq_bins, mel_time_step)\n    batches_token_ids = [token_ids[idx*batch_size : (idx+1)*batch_size] for idx in range(batches_len)]\n\n    # ctc loss label associated values\n    sent_b_len = len(batches_token_ids)\n    # flattened_batches_token_ids = torch.cat([torch.as_tensor(seq, dtype=torch.long) for seq in batches_token_ids])\n    flattened_batches_token_ids = [\n        torch.cat([torch.as_tensor(seq, dtype=torch.long) for seq in batch]) for batch in batches_token_ids\n        ]\n    \n    # ctc loss parameters\n    input_length = torch.stack([\n        torch.tensor(original_mel_lengths[idx*batch_size : (idx+1)*batch_size], dtype=torch.long)\n        for idx in range(batches_len)\n    ])\n\n    label_length = torch.stack([\n        torch.tensor([len(seq) for seq in batch], dtype=torch.long)\n        for batch in batches_token_ids\n    ])\n\n    # print(f'batched audios shape: {batches_audio.shape}')\n    # print(f'batched token_ids shape: {sent_b_len, len(batches_token_ids[random.randint(0, sent_b_len)])}')\n    # print(f'ctc loss, \\ninput: {input_length} \\nlabel: {label_length}')\n\n    return list(zip(batches_audio, flattened_batches_token_ids, input_length, label_length))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:39:47.166896Z","iopub.execute_input":"2025-04-09T11:39:47.167203Z","iopub.status.idle":"2025-04-09T11:39:47.174903Z","shell.execute_reply.started":"2025-04-09T11:39:47.167179Z","shell.execute_reply":"2025-04-09T11:39:47.173997Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"simulation_dataset = mel_loader_2(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:10.544373Z","iopub.execute_input":"2025-04-09T11:27:10.544622Z","iopub.status.idle":"2025-04-09T11:27:14.248276Z","shell.execute_reply.started":"2025-04-09T11:27:10.544592Z","shell.execute_reply":"2025-04-09T11:27:14.247596Z"}},"outputs":[{"name":"stdout","text":"[INFO] Auto-set mel_time_step to max found: 361\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"simulation_dataset[56][0].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:14.249185Z","iopub.execute_input":"2025-04-09T11:27:14.249485Z","iopub.status.idle":"2025-04-09T11:27:14.254282Z","shell.execute_reply.started":"2025-04-09T11:27:14.249449Z","shell.execute_reply":"2025-04-09T11:27:14.253611Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 128, 361])"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"simulation_dataset[56][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:14.254931Z","iopub.execute_input":"2025-04-09T11:27:14.255143Z","iopub.status.idle":"2025-04-09T11:27:14.271640Z","shell.execute_reply.started":"2025-04-09T11:27:14.255124Z","shell.execute_reply":"2025-04-09T11:27:14.270994Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"tensor([11, 27, 21, 14, 24, 25,  6, 26, 29, 21, 34, 25, 35,  5, 26, 31, 32, 33])"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"simulation_dataset[56][2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:14.272564Z","iopub.execute_input":"2025-04-09T11:27:14.272862Z","iopub.status.idle":"2025-04-09T11:27:14.286699Z","shell.execute_reply.started":"2025-04-09T11:27:14.272835Z","shell.execute_reply":"2025-04-09T11:27:14.286057Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"tensor([58, 71, 75, 78])"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"simulation_dataset[56][3]","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:14.287389Z","iopub.execute_input":"2025-04-09T11:27:14.287618Z","iopub.status.idle":"2025-04-09T11:27:14.301955Z","shell.execute_reply.started":"2025-04-09T11:27:14.287599Z","shell.execute_reply":"2025-04-09T11:27:14.301284Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"tensor([3, 3, 7, 5])"},"metadata":{}}],"execution_count":37},{"cell_type":"markdown","source":"# MODEL","metadata":{}},{"cell_type":"markdown","source":"## model 1","metadata":{}},{"cell_type":"code","source":"class DeepSpeech(nn.Module):\n    def __init__(\n        self, \n        in_channels=128, \n        hidden_dim=256, \n        num_classes=35, \n        num_layers=3, \n        bidirectional=True,\n        dp=0.1\n    ):\n        super(DeepSpeech, self).__init__()\n\n        self.conv = nn.Sequential(\n            nn.Conv1d(in_channels, 128, kernel_size=3, padding=1),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Conv1d(256, 512, kernel_size=3, padding=1),\n            nn.BatchNorm1d(512),\n            nn.ReLU()\n        )\n        self.d = nn.Dropout(dp)\n        self.rnn = nn.LSTM(\n            input_size=512,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            bidirectional=bidirectional\n        )\n\n        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, num_classes)\n        self.softmax = nn.LogSoftmax(dim=-1)\n\n    def forward(self, x):  # x: (B, C, T)\n        x = self.conv(x)           # (B, 512, T)\n        x = x.permute(0, 2, 1)     # (B, T, 512)\n        x = self.d(x)\n        x, _ = self.rnn(x)         # (B, T, H*2)\n        x = self.fc(x)             # (B, T, num_classes)\n        x = self.softmax(x)        # (B, T, num_classes)\n        x = x.permute(1, 0, 2)     # (T, B, num_classes)\n        return x\n\nmodel1 = DeepSpeech().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:14.302603Z","iopub.execute_input":"2025-04-09T11:27:14.302814Z","iopub.status.idle":"2025-04-09T11:27:14.610961Z","shell.execute_reply.started":"2025-04-09T11:27:14.302795Z","shell.execute_reply":"2025-04-09T11:27:14.610319Z"}},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":"## opt & loss","metadata":{}},{"cell_type":"code","source":"optimizer = optim.Adam(model1.parameters(), lr=1e-3)\n\noptimizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:14.611667Z","iopub.execute_input":"2025-04-09T11:27:14.611910Z","iopub.status.idle":"2025-04-09T11:27:16.542888Z","shell.execute_reply.started":"2025-04-09T11:27:14.611891Z","shell.execute_reply":"2025-04-09T11:27:16.542166Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"criterion = CTCLoss(blank=0, zero_infinity=True, reduction='mean')\n\ncriterion","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:16.543615Z","iopub.execute_input":"2025-04-09T11:27:16.544103Z","iopub.status.idle":"2025-04-09T11:27:16.548767Z","shell.execute_reply.started":"2025-04-09T11:27:16.544080Z","shell.execute_reply":"2025-04-09T11:27:16.547946Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"CTCLoss()"},"metadata":{}}],"execution_count":40},{"cell_type":"markdown","source":"## summary","metadata":{}},{"cell_type":"code","source":"summary(model1, (4, 128, 298))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:16.549550Z","iopub.execute_input":"2025-04-09T11:27:16.549862Z","iopub.status.idle":"2025-04-09T11:27:17.117939Z","shell.execute_reply.started":"2025-04-09T11:27:16.549832Z","shell.execute_reply":"2025-04-09T11:27:17.117063Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nDeepSpeech                               [298, 4, 35]              --\n├─Sequential: 1-1                        [4, 512, 298]             --\n│    └─Conv1d: 2-1                       [4, 128, 298]             49,280\n│    └─BatchNorm1d: 2-2                  [4, 128, 298]             256\n│    └─ReLU: 2-3                         [4, 128, 298]             --\n│    └─Conv1d: 2-4                       [4, 256, 298]             98,560\n│    └─BatchNorm1d: 2-5                  [4, 256, 298]             512\n│    └─ReLU: 2-6                         [4, 256, 298]             --\n│    └─Conv1d: 2-7                       [4, 512, 298]             393,728\n│    └─BatchNorm1d: 2-8                  [4, 512, 298]             1,024\n│    └─ReLU: 2-9                         [4, 512, 298]             --\n├─Dropout: 1-2                           [4, 298, 512]             --\n├─LSTM: 1-3                              [4, 298, 512]             4,730,880\n├─Linear: 1-4                            [4, 298, 35]              17,955\n├─LogSoftmax: 1-5                        [4, 298, 35]              --\n==========================================================================================\nTotal params: 5,292,195\nTrainable params: 5,292,195\nNon-trainable params: 0\nTotal mult-adds (G): 6.28\n==========================================================================================\nInput size (MB): 0.61\nForward/backward pass size (MB): 22.30\nParams size (MB): 21.17\nEstimated Total Size (MB): 44.08\n=========================================================================================="},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"sum(p.numel() for p in model1.parameters())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:17.118737Z","iopub.execute_input":"2025-04-09T11:27:17.118976Z","iopub.status.idle":"2025-04-09T11:27:17.123879Z","shell.execute_reply.started":"2025-04-09T11:27:17.118956Z","shell.execute_reply":"2025-04-09T11:27:17.123182Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"5292195"},"metadata":{}}],"execution_count":42},{"cell_type":"markdown","source":"# CHECKPOINT","metadata":{}},{"cell_type":"code","source":"def save_model(path_v, epoch, b_idx, model, optimizer, training_losses):\n    \n    # create dir if not exists\n    os.makedirs(path_v, exist_ok=True)\n    existing_files = [\n        f for f in os.listdir(path_v) if f.endswith('.pth') and f.startswith('model')]\n    versions = []\n    \n    # get the latest version\n    for file in existing_files:\n        filename = file.replace('.pth', '').split('_')\n        if len(filename) > 1 and filename[-1].isdigit():\n            versions.append(int(filename[-1]))\n    new_version = max(versions)+1 if versions else 1\n\n    # model checkpoint collection\n    checkpoint = {\n        'epoch': epoch,\n        'batch_index': b_idx,\n        'time': datetime.now(),\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'training_losses': training_losses,\n    }\n    \n    # save checkpoint into new path\n    new_path = os.path.join(path_v, f'model1_100percent_{new_version}.pth')\n    torch.save(checkpoint, new_path)\n    \n    print(f'MODEL SAVED AT {new_path}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:17.124535Z","iopub.execute_input":"2025-04-09T11:27:17.124830Z","iopub.status.idle":"2025-04-09T11:27:17.141142Z","shell.execute_reply.started":"2025-04-09T11:27:17.124798Z","shell.execute_reply":"2025-04-09T11:27:17.140462Z"}},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":"# TRAINING","metadata":{}},{"cell_type":"markdown","source":"## train","metadata":{}},{"cell_type":"code","source":"def log_to_file(filepath, message):\n    \"\"\"Appends a message to a file, creating the file if it doesn't exist.\"\"\"\n    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n    with open(filepath, 'a', encoding='utf-8') as f:\n        f.write(message + '\\n')\n\ndef train(model, dataloader, optimizer, criterion, device, save_model, model_dir, model_name, epochs=10):\n    \n    model.train()\n    training_losses = []\n    \n    # File paths\n    log_file = os.path.join(model_dir, model_name + '_train_history.txt')              # detailed logs\n    epoch_loss_file = os.path.join(model_dir, model_name + '_epoch_losses.txt')       # epoch loss only\n    batch_loss_file = os.path.join(model_dir, model_name + '_batch_losses.txt')       # batch loss only\n\n    for epoch in range(epochs):\n        epoch_start = time.perf_counter()\n        \n        total_loss = 0.0\n        running_batch_loss = 0.0\n        log_batch_interval = 1000\n        \n        print(f\"\\n=== Starting Epoch {epoch + 1} ===\")\n\n        for idx, (mel_array, token_ids, input_length, label_length) in enumerate(dataloader):\n            batch_start = time.perf_counter()\n\n            optimizer.zero_grad()\n            outputs = model(mel_array.to(device))\n            log_probs = F.log_softmax(outputs, dim=2)\n\n            T = log_probs.size(0)\n            if torch.any(input_length > T):\n                input_length = torch.clamp(input_length, max=T)\n\n            loss = criterion(\n                log_probs,\n                token_ids.to(device),\n                input_length.to(device),\n                label_length.to(device)\n            )\n\n            loss_value = loss.item()\n            total_loss += loss_value\n            running_batch_loss += loss_value\n\n            loss.backward()\n            optimizer.step()\n\n            batch_time = time.perf_counter() - batch_start\n\n            # Logging every log_batch_interval or at the end\n            if (idx + 1) % log_batch_interval == 0 or idx == len(dataloader) - 1:\n                # Handle division correctly\n                divisor = log_batch_interval if (idx + 1) % log_batch_interval == 0 else (idx + 1) % log_batch_interval\n                avg_loss = running_batch_loss / divisor\n\n                msg = (\n                    f\"[{datetime.now()}] Epoch {epoch + 1}, Batch {idx + 1}, \"\n                    f\"{divisor} Batches Mean Loss: {avg_loss:.4f}, Time: {batch_time:.2f}s\"\n                )\n                print(msg)\n                log_to_file(log_file, msg)\n                log_to_file(batch_loss_file, f\"{avg_loss:.4f}\")\n                running_batch_loss = 0.0  # reset\n\n        epoch_time = time.perf_counter() - epoch_start\n\n        log_to_file(epoch_loss_file, f\"{total_loss:.4f}\")\n        training_losses.append(total_loss)\n\n        epoch_msg = (\n            f\"\\n[{datetime.now()}] EPOCH {epoch + 1} COMPLETED - \"\n            f\"Total Loss: {total_loss:.4f}, Time: {epoch_time:.2f}s\\n\"\n        )\n        print(epoch_msg)\n        log_to_file(log_file, epoch_msg)\n\n        save_model(model_dir, epoch + 1, idx, model, optimizer, training_losses)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:17.141913Z","iopub.execute_input":"2025-04-09T11:27:17.142191Z","iopub.status.idle":"2025-04-09T11:27:17.164231Z","shell.execute_reply.started":"2025-04-09T11:27:17.142159Z","shell.execute_reply":"2025-04-09T11:27:17.163521Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"\"\"\"model_path = os.path.join(TARGET_DIR, 'models/model1')\n\nos.makedirs(model_path, exist_ok=True)\n\ntrain(\n    model1, \n    mel_loader_2(X_train, y_train), \n    optimizer, criterion, device, \n    save_model, model_path, 'model1', \n    epochs=20\n)\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:17.164934Z","iopub.execute_input":"2025-04-09T11:27:17.165120Z","iopub.status.idle":"2025-04-09T11:27:17.181943Z","shell.execute_reply.started":"2025-04-09T11:27:17.165103Z","shell.execute_reply":"2025-04-09T11:27:17.181201Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"\"model_path = os.path.join(TARGET_DIR, 'models/model1')\\n\\nos.makedirs(model_path, exist_ok=True)\\n\\ntrain(\\n    model1, \\n    mel_loader_2(X_train, y_train), \\n    optimizer, criterion, device, \\n    save_model, model_path, 'model1', \\n    epochs=20\\n)\""},"metadata":{}}],"execution_count":45},{"cell_type":"markdown","source":"# EVALUATION","metadata":{}},{"cell_type":"markdown","source":"## sample","metadata":{}},{"cell_type":"code","source":"import random\n\ntest_num = random.randint(0, len(X_test)-1)\n\ntest_num","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:43:33.371163Z","iopub.execute_input":"2025-04-09T11:43:33.371498Z","iopub.status.idle":"2025-04-09T11:43:33.376868Z","shell.execute_reply.started":"2025-04-09T11:43:33.371475Z","shell.execute_reply":"2025-04-09T11:43:33.375962Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"844"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"test_sample = X_test[test_num]\n\ntest_sample.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:17.199183Z","iopub.execute_input":"2025-04-09T11:27:17.199460Z","iopub.status.idle":"2025-04-09T11:27:17.212807Z","shell.execute_reply.started":"2025-04-09T11:27:17.199432Z","shell.execute_reply":"2025-04-09T11:27:17.212005Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"torch.Size([128, 80])"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"test_sample_queeze = test_sample.unsqueeze(0).to(device)\n\ntest_sample_queeze.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:17.213617Z","iopub.execute_input":"2025-04-09T11:27:17.213917Z","iopub.status.idle":"2025-04-09T11:27:17.227912Z","shell.execute_reply.started":"2025-04-09T11:27:17.213890Z","shell.execute_reply":"2025-04-09T11:27:17.227129Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 128, 80])"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"test_label = y_test[test_num].tolist()\n\ntest_label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:17.228628Z","iopub.execute_input":"2025-04-09T11:27:17.228898Z","iopub.status.idle":"2025-04-09T11:27:17.242371Z","shell.execute_reply.started":"2025-04-09T11:27:17.228878Z","shell.execute_reply":"2025-04-09T11:27:17.241759Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"[10, 26, 27, 21]"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"test_label = tokenizer.decode(test_label)\n\ntest_label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:17.243009Z","iopub.execute_input":"2025-04-09T11:27:17.243186Z","iopub.status.idle":"2025-04-09T11:27:17.258313Z","shell.execute_reply.started":"2025-04-09T11:27:17.243170Z","shell.execute_reply":"2025-04-09T11:27:17.257522Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"'n ##i ##n ##e'"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"test_word = detokenize(test_label)\n\ntest_word","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:17.259183Z","iopub.execute_input":"2025-04-09T11:27:17.259480Z","iopub.status.idle":"2025-04-09T11:27:17.272893Z","shell.execute_reply.started":"2025-04-09T11:27:17.259435Z","shell.execute_reply":"2025-04-09T11:27:17.272111Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"'nine'"},"metadata":{}}],"execution_count":51},{"cell_type":"markdown","source":"## before","metadata":{}},{"cell_type":"code","source":"test_output_bf = model1(test_sample_queeze)\n\ntest_output_bf.shape, test_output_bf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:17.273854Z","iopub.execute_input":"2025-04-09T11:27:17.274136Z","iopub.status.idle":"2025-04-09T11:27:17.560322Z","shell.execute_reply.started":"2025-04-09T11:27:17.274108Z","shell.execute_reply":"2025-04-09T11:27:17.559580Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"(torch.Size([80, 1, 35]),\n tensor([[[-3.5878, -3.5924, -3.5538,  ..., -3.5849, -3.5397, -3.6085]],\n \n         [[-3.5881, -3.5899, -3.5540,  ..., -3.5849, -3.5402, -3.6108]],\n \n         [[-3.5880, -3.5882, -3.5536,  ..., -3.5847, -3.5390, -3.6130]],\n \n         ...,\n \n         [[-3.5838, -3.5819, -3.5465,  ..., -3.5824, -3.5366, -3.6137]],\n \n         [[-3.5816, -3.5821, -3.5445,  ..., -3.5802, -3.5350, -3.6120]],\n \n         [[-3.5806, -3.5820, -3.5427,  ..., -3.5772, -3.5320, -3.6091]]],\n        device='cuda:0', grad_fn=<PermuteBackward0>))"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"test_pred_bf = test_output_bf.argmax(dim=2)\n\ntest_pred_bf.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:17.561141Z","iopub.execute_input":"2025-04-09T11:27:17.561460Z","iopub.status.idle":"2025-04-09T11:27:17.577183Z","shell.execute_reply.started":"2025-04-09T11:27:17.561426Z","shell.execute_reply":"2025-04-09T11:27:17.576558Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"torch.Size([80, 1])"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"test_token_bf = ' '.join([tokenizer.decode(p) for p in test_pred_bf.tolist()])\n\ntest_token_bf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:17.577872Z","iopub.execute_input":"2025-04-09T11:27:17.578127Z","iopub.status.idle":"2025-04-09T11:27:17.583198Z","shell.execute_reply.started":"2025-04-09T11:27:17.578093Z","shell.execute_reply":"2025-04-09T11:27:17.582528Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"'##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u t t t t t t t t t t t ##u ##u ##u t t t t t t t t t t t t t t t ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u ##u t t t t'"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"test_word_bf = detokenize(test_token_bf)\n\ntest_word_bf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:17.584011Z","iopub.execute_input":"2025-04-09T11:27:17.584226Z","iopub.status.idle":"2025-04-09T11:27:17.598409Z","shell.execute_reply.started":"2025-04-09T11:27:17.584208Z","shell.execute_reply":"2025-04-09T11:27:17.597605Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"'uuuuuuuuuuuuuuuuuutttttttttttuuutttttttttttttttuuuuuuuuuuuuuuuuuuuuuuuuuuuuutttt'"},"metadata":{}}],"execution_count":55},{"cell_type":"markdown","source":"## after","metadata":{}},{"cell_type":"code","source":"model1_v2_state = torch.load('/kaggle/input/stn-v5-v2/pytorch/default/1/model1_100percent_20_v2.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:17.599198Z","iopub.execute_input":"2025-04-09T11:27:17.599432Z","iopub.status.idle":"2025-04-09T11:27:18.448513Z","shell.execute_reply.started":"2025-04-09T11:27:17.599402Z","shell.execute_reply":"2025-04-09T11:27:18.447613Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-56-51fb21fcff93>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model1_v2_state = torch.load('/kaggle/input/stn-v5-v2/pytorch/default/1/model1_100percent_20_v2.pth')\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"model1_v2 = DeepSpeech().to(device)\n\nmodel1_v2.load_state_dict(model1_v2_state['model_state_dict'])\n\nmodel1_v2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:18.449396Z","iopub.execute_input":"2025-04-09T11:27:18.449639Z","iopub.status.idle":"2025-04-09T11:27:18.499436Z","shell.execute_reply.started":"2025-04-09T11:27:18.449606Z","shell.execute_reply":"2025-04-09T11:27:18.498824Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"DeepSpeech(\n  (conv): Sequential(\n    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU()\n    (6): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n    (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU()\n  )\n  (d): Dropout(p=0.1, inplace=False)\n  (rnn): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n  (fc): Linear(in_features=512, out_features=35, bias=True)\n  (softmax): LogSoftmax(dim=-1)\n)"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"test_output_af = model1_v2(test_sample_queeze)\n\ntest_output_af.shape, test_output_af","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:18.500275Z","iopub.execute_input":"2025-04-09T11:27:18.500513Z","iopub.status.idle":"2025-04-09T11:27:18.517250Z","shell.execute_reply.started":"2025-04-09T11:27:18.500492Z","shell.execute_reply":"2025-04-09T11:27:18.516607Z"}},"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"(torch.Size([80, 1, 35]),\n tensor([[[-11.3342, -18.9402, -19.1254,  ..., -12.6722, -14.5565, -14.7109]],\n \n         [[-13.2726, -21.8535, -21.9038,  ..., -14.6472, -21.7528, -20.4907]],\n \n         [[ -4.7978, -26.2927, -26.4185,  ...,  -7.2978, -11.8023, -13.4523]],\n \n         ...,\n \n         [[  0.0000, -46.2486, -45.8232,  ..., -29.5323, -38.1030, -22.5055]],\n \n         [[  0.0000, -50.1764, -49.7196,  ..., -30.9108, -42.1057, -25.2078]],\n \n         [[  0.0000, -47.6195, -47.2245,  ..., -30.2861, -39.3181, -25.1856]]],\n        device='cuda:0', grad_fn=<PermuteBackward0>))"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"test_pred_af = test_output_af.argmax(dim=2)\n\ntest_pred_af.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:18.518101Z","iopub.execute_input":"2025-04-09T11:27:18.518396Z","iopub.status.idle":"2025-04-09T11:27:18.523256Z","shell.execute_reply.started":"2025-04-09T11:27:18.518366Z","shell.execute_reply":"2025-04-09T11:27:18.522460Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"torch.Size([80, 1])"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"test_token_af = ' '.join([tokenizer.decode(p) for p in test_pred_af.tolist()])\n\ntest_token_af","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:18.524180Z","iopub.execute_input":"2025-04-09T11:27:18.524482Z","iopub.status.idle":"2025-04-09T11:27:18.538531Z","shell.execute_reply.started":"2025-04-09T11:27:18.524453Z","shell.execute_reply":"2025-04-09T11:27:18.537953Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"'n ##e ##s ##y                                                                            '"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"detokenize(test_token_af)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:27:18.539282Z","iopub.execute_input":"2025-04-09T11:27:18.539585Z","iopub.status.idle":"2025-04-09T11:27:18.553040Z","shell.execute_reply.started":"2025-04-09T11:27:18.539557Z","shell.execute_reply":"2025-04-09T11:27:18.552278Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"'nesy'"},"metadata":{}}],"execution_count":61},{"cell_type":"markdown","source":"### evaluate","metadata":{}},{"cell_type":"code","source":"pip install levenshtein","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:55:34.578034Z","iopub.execute_input":"2025-04-09T11:55:34.578328Z","iopub.status.idle":"2025-04-09T11:55:41.197349Z","shell.execute_reply.started":"2025-04-09T11:55:34.578307Z","shell.execute_reply":"2025-04-09T11:55:41.196442Z"}},"outputs":[{"name":"stdout","text":"Collecting levenshtein\n  Downloading levenshtein-0.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nCollecting rapidfuzz<4.0.0,>=3.9.0 (from levenshtein)\n  Downloading rapidfuzz-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nDownloading levenshtein-0.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.5/161.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rapidfuzz-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, levenshtein\nSuccessfully installed levenshtein-0.27.1 rapidfuzz-3.13.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"from Levenshtein import distance\n\ndef levenshtein_percetage(model, X_sample, y_sample):\n    model.eval().to(device)\n    random_num = random.randint(0, len(X_sample)-1)\n    \n    test_ids = y_sample[random_num].tolist()\n    test_token = tokenizer.decode(test_ids)\n    test_word = detokenize(test_token)\n    \n    test_mels = X_sample[random_num].unsqueeze(0)\n    output = model(test_mels.to(device))\n    preds = output.argmax(dim=2)\n    tokens = [tokenizer.decode(ids) for ids in preds.tolist()]\n    predicted_word = detokenize(' '.join(tokens))\n\n    #return test_word, predicted_word\n    max_len = max(len(test_word), len(predicted_word))\n    acc = (1-abs(distance(test_word, predicted_word)/max_len)) * 100\n    acc_str = f'Speech to Command Model has {acc:.4f}% accuracy. Label word: {test_word} / Predicted word: {predicted_word}'\n    return acc_str","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T12:05:36.794503Z","iopub.execute_input":"2025-04-09T12:05:36.794822Z","iopub.status.idle":"2025-04-09T12:05:36.800342Z","shell.execute_reply.started":"2025-04-09T12:05:36.794796Z","shell.execute_reply":"2025-04-09T12:05:36.799631Z"}},"outputs":[],"execution_count":116},{"cell_type":"code","source":"levenshtein_percetage(model1_v2, X_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T12:05:38.231280Z","iopub.execute_input":"2025-04-09T12:05:38.231576Z","iopub.status.idle":"2025-04-09T12:05:38.248031Z","shell.execute_reply.started":"2025-04-09T12:05:38.231553Z","shell.execute_reply":"2025-04-09T12:05:38.247409Z"}},"outputs":[{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"'Speech to Command Model has 0.0000% accuracy. Label word: nine / Predicted word: foo'"},"metadata":{}}],"execution_count":117},{"cell_type":"code","source":"def evaluate(model, dataloader, criterion, device, model_dir, model_name):\n    model.eval()\n    total_loss = 0.0\n    num_batches = 0\n\n    # File paths\n    log_file = os.path.join(model_dir, model_name + '_eval_history.txt')\n    loss_file = os.path.join(model_dir, model_name + '_eval_loss.txt')\n\n    start_time = time.perf_counter()\n    with torch.no_grad():\n        for idx, (mel_array, token_ids, input_length, label_length) in enumerate(dataloader):\n            outputs = model(mel_array.to(device))\n            log_probs = F.log_softmax(outputs, dim=2)\n\n            T = log_probs.size(0)\n            if torch.any(input_length > T):\n                input_length = torch.clamp(input_length, max=T)\n\n            loss = criterion(\n                log_probs,\n                token_ids.to(device),\n                input_length.to(device),\n                label_length.to(device)\n            )\n            total_loss += loss.item()\n            num_batches += 1\n\n    mean_loss = total_loss / num_batches if num_batches > 0 else 0.0\n    elapsed = time.perf_counter() - start_time\n\n    msg = (\n        f\"\\n[{datetime.now()}] EVALUATION COMPLETED\\n\"\n        f\"Total Loss: {total_loss:.4f}\\n\"\n        f\"Mean Loss: {mean_loss:.4f} over {num_batches} batches\\n\"\n        f\"Time: {elapsed:.2f}s\\n\"\n    )\n    print(msg)\n    log_to_file(log_file, msg)\n    log_to_file(loss_file, f\"Total Loss: {total_loss:.4f}\")\n    log_to_file(loss_file, f\"Mean Loss: {mean_loss:.4f}\")\n\n    return total_loss, mean_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:39:18.391982Z","iopub.execute_input":"2025-04-09T11:39:18.392270Z","iopub.status.idle":"2025-04-09T11:39:18.398789Z","shell.execute_reply.started":"2025-04-09T11:39:18.392248Z","shell.execute_reply":"2025-04-09T11:39:18.398044Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"len(X_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:30:43.417740Z","iopub.execute_input":"2025-04-09T11:30:43.418030Z","iopub.status.idle":"2025-04-09T11:30:43.422534Z","shell.execute_reply.started":"2025-04-09T11:30:43.418008Z","shell.execute_reply":"2025-04-09T11:30:43.421938Z"}},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"13028"},"metadata":{}}],"execution_count":68},{"cell_type":"code","source":"len(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:30:32.983757Z","iopub.execute_input":"2025-04-09T11:30:32.984053Z","iopub.status.idle":"2025-04-09T11:30:32.989033Z","shell.execute_reply.started":"2025-04-09T11:30:32.984031Z","shell.execute_reply":"2025-04-09T11:30:32.988348Z"}},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"3257"},"metadata":{}}],"execution_count":67},{"cell_type":"code","source":"model_path = os.path.join(TARGET_DIR, 'models/model1')\n\nos.makedirs(model_path, exist_ok=True)\n\neva_total_loss, eva_mean_loss = evaluate(\n    model1_v2, \n    mel_loader_2(X_test, y_test), \n    criterion, \n    device, \n    model_path, \n    'model1'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:40:56.082814Z","iopub.execute_input":"2025-04-09T11:40:56.083115Z","iopub.status.idle":"2025-04-09T11:41:18.621211Z","shell.execute_reply.started":"2025-04-09T11:40:56.083094Z","shell.execute_reply":"2025-04-09T11:41:18.620419Z"}},"outputs":[{"name":"stdout","text":"[INFO] Auto-set mel_time_step to max found: 309\n\n[2025-04-09 11:41:18.570281] EVALUATION COMPLETED\nTotal Loss: 6922.3166\nMean Loss: 8.5041 over 814 batches\nTime: 22.05s\n\n","output_type":"stream"}],"execution_count":75}]}