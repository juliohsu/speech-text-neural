{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTALLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T23:48:29.158187Z",
     "iopub.status.busy": "2025-03-23T23:48:29.157905Z",
     "iopub.status.idle": "2025-03-23T23:48:32.798054Z",
     "shell.execute_reply": "2025-03-23T23:48:32.796813Z",
     "shell.execute_reply.started": "2025-03-23T23:48:29.158167Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.29.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-23T23:48:32.799846Z",
     "iopub.status.busy": "2025-03-23T23:48:32.799582Z",
     "iopub.status.idle": "2025-03-23T23:48:32.804982Z",
     "shell.execute_reply": "2025-03-23T23:48:32.804268Z",
     "shell.execute_reply.started": "2025-03-23T23:48:32.799823Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T23:48:32.807148Z",
     "iopub.status.busy": "2025-03-23T23:48:32.806904Z",
     "iopub.status.idle": "2025-03-23T23:48:32.944791Z",
     "shell.execute_reply": "2025-03-23T23:48:32.944203Z",
     "shell.execute_reply.started": "2025-03-23T23:48:32.807129Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# neural network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "\n",
    "# data download (hugging face)\n",
    "from datasets import load_dataset, Audio\n",
    "from huggingface_hub import login\n",
    "\n",
    "# data preprocessing\n",
    "from transformers import Wav2Vec2Processor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# evaluation\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use o logging da conta do seu hugging face\n",
    "\n",
    "#login('xxxxx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T23:48:32.946053Z",
     "iopub.status.busy": "2025-03-23T23:48:32.945857Z",
     "iopub.status.idle": "2025-03-23T23:48:32.951676Z",
     "shell.execute_reply": "2025-03-23T23:48:32.950948Z",
     "shell.execute_reply.started": "2025-03-23T23:48:32.946035Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hardware status\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T23:48:32.952649Z",
     "iopub.status.busy": "2025-03-23T23:48:32.952395Z",
     "iopub.status.idle": "2025-03-23T23:48:32.965950Z",
     "shell.execute_reply": "2025-03-23T23:48:32.965021Z",
     "shell.execute_reply.started": "2025-03-23T23:48:32.952610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# first version speed-text model network\n",
    "class STN1(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(STN1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=(1, 10))\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=(1, 10))\n",
    "        self.drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, vocab_size)\n",
    "    def forward(self, x):\n",
    "        # Ensure the input tensor has 4 dimensions\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(1)\n",
    "        \n",
    "        x = f.relu(self.conv1(x))\n",
    "        x = f.relu(self.conv2(x))\n",
    "        x = self.drop(x)\n",
    "\n",
    "        # Dynamically calculate the flattened size\n",
    "        batch_size = x.size(0)\n",
    "        flattened_size = x.size(1) * x.size(2) * x.size(3)\n",
    "        x = x.view(batch_size, -1)\n",
    "        \n",
    "        x = f.relu(self.fc1(x))\n",
    "        return f.log_softmax(self.fc2(x), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T23:48:32.966894Z",
     "iopub.status.busy": "2025-03-23T23:48:32.966716Z",
     "iopub.status.idle": "2025-03-23T23:48:33.511329Z",
     "shell.execute_reply": "2025-03-23T23:48:33.510599Z",
     "shell.execute_reply.started": "2025-03-23T23:48:32.966877Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Processor:\n",
       "- feature_extractor: Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"return_attention_mask\": false,\n",
       "  \"sampling_rate\": 16000\n",
       "}\n",
       "\n",
       "- tokenizer: Wav2Vec2CTCTokenizer(name_or_path='facebook/wav2vec2-base-960h', vocab_size=32, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<pad>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n",
       "\t1: AddedToken(\"<s>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n",
       "\t2: AddedToken(\"</s>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n",
       "}\n",
       ")\n",
       "\n",
       "{\n",
       "  \"processor_class\": \"Wav2Vec2Processor\"\n",
       "}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processor for input (audio signal) and output (text) conversion\n",
    "processor = Wav2Vec2Processor.from_pretrained('facebook/wav2vec2-base-960h')\n",
    "\n",
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T23:48:33.512381Z",
     "iopub.status.busy": "2025-03-23T23:48:33.512123Z",
     "iopub.status.idle": "2025-03-23T23:48:34.592523Z",
     "shell.execute_reply": "2025-03-23T23:48:34.591827Z",
     "shell.execute_reply.started": "2025-03-23T23:48:33.512349Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
       "    num_shards: 24\n",
       "})"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load mozilla foundation, commom voice v11, training dataset from hugging face\n",
    "ds_train = load_dataset('mozilla-foundation/common_voice_11_0', 'en', split='train', streaming=True)\n",
    "\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T23:48:34.593375Z",
     "iopub.status.busy": "2025-03-23T23:48:34.593184Z",
     "iopub.status.idle": "2025-03-23T23:48:34.597801Z",
     "shell.execute_reply": "2025-03-23T23:48:34.596916Z",
     "shell.execute_reply.started": "2025-03-23T23:48:34.593358Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# method to process each row of dataset, audio array into dimensional features and text into numbers\n",
    "def prepare_batch(batch):\n",
    "    input_values = processor(batch['audio']['array'], sampling_rate=16_000).input_values[0]\n",
    "    labels = processor.tokenizer(batch['sentence'], return_attention_mask=False).input_ids\n",
    "    batch['input_values'] = input_values\n",
    "    batch['labels'] = labels\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T23:48:34.600259Z",
     "iopub.status.busy": "2025-03-23T23:48:34.600066Z",
     "iopub.status.idle": "2025-03-23T23:48:34.615969Z",
     "shell.execute_reply": "2025-03-23T23:48:34.615281Z",
     "shell.execute_reply.started": "2025-03-23T23:48:34.600242Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: Unknown,\n",
       "    num_shards: 24\n",
       "})"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply method above and align audio sampling rate with the method\n",
    "ds_train = ds_train.cast_column('audio', Audio(sampling_rate=16_000))\n",
    "ds_train = ds_train.map(prepare_batch)\n",
    "\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T23:48:34.617471Z",
     "iopub.status.busy": "2025-03-23T23:48:34.617206Z",
     "iopub.status.idle": "2025-03-23T23:48:34.628772Z",
     "shell.execute_reply": "2025-03-23T23:48:34.627980Z",
     "shell.execute_reply.started": "2025-03-23T23:48:34.617428Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# extraction of batch input and label values into dataloader streamline\\ndef collate_fn(batch):\\n    # extract target cols\\n    input_values = [item['input_values'] for item in batch]\\n    labels = [item['labels'] for item in batch]\\n\\n    # if tensor, convert to numpy first\\n    if isinstance(input_values[0], torch.Tensor):\\n        input_values = [x.tolist() for x in input_values]\\n\\n    # calculate padding, to align all element into same length\\n    max_len = max((len(x) if isinstance(x, list) else x.shape[0]) for x in input_values)\\n    padded_inputs = [x + [0] * (max_len - len(x)) for x in input_values]\\n    input_tensor = torch.tensor(padded_inputs, dtype=torch.float32)\\n\\n    # calculate padding, to align all element into same length\\n    max_len2 = max(len(label) for label in labels)\\n    padded_labels = [label + [processor.tokenizer.eos_token_id] * (max_len2 - len(label)) for label in labels]\\n    label_tensor = torch.tensor(padded_labels)\\n    \\n    return input_tensor, label_tensor\""
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# extraction of batch input and label values into dataloader streamline\n",
    "def collate_fn(batch):\n",
    "    # extract target cols\n",
    "    input_values = [item['input_values'] for item in batch]\n",
    "    labels = [item['labels'] for item in batch]\n",
    "\n",
    "    # if tensor, convert to numpy first\n",
    "    if isinstance(input_values[0], torch.Tensor):\n",
    "        input_values = [x.tolist() for x in input_values]\n",
    "\n",
    "    # calculate padding, to align all element into same length\n",
    "    max_len = max((len(x) if isinstance(x, list) else x.shape[0]) for x in input_values)\n",
    "    padded_inputs = [x + [0] * (max_len - len(x)) for x in input_values]\n",
    "    input_tensor = torch.tensor(padded_inputs, dtype=torch.float32)\n",
    "\n",
    "    # calculate padding, to align all element into same length\n",
    "    max_len2 = max(len(label) for label in labels)\n",
    "    padded_labels = [label + [processor.tokenizer.eos_token_id] * (max_len2 - len(label)) for label in labels]\n",
    "    label_tensor = torch.tensor(padded_labels)\n",
    "    \n",
    "    return input_tensor, label_tensor\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T23:48:34.629789Z",
     "iopub.status.busy": "2025-03-23T23:48:34.629581Z",
     "iopub.status.idle": "2025-03-23T23:48:34.640287Z",
     "shell.execute_reply": "2025-03-23T23:48:34.639433Z",
     "shell.execute_reply.started": "2025-03-23T23:48:34.629772Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Extract input_values and labels from the batch\n",
    "    input_values = [item['input_values'] for item in batch]\n",
    "    labels = [item['labels'] for item in batch]\n",
    "\n",
    "    # Convert tensors to lists if necessary\n",
    "    if isinstance(input_values[0], torch.Tensor):\n",
    "        input_values = [x.numpy() for x in input_values]  # Convert to NumPy for efficient padding\n",
    "\n",
    "    # Pad input_values to the same length\n",
    "    max_len = max(len(x) for x in input_values)\n",
    "    padded_inputs = np.array([np.pad(x, (0, max_len - len(x)), mode='constant', constant_values=0) for x in input_values])\n",
    "    input_tensor = torch.tensor(padded_inputs, dtype=torch.float32)\n",
    "\n",
    "    # Pad labels to the same length\n",
    "    max_len2 = max(len(label) for label in labels)\n",
    "    padded_labels = np.array([np.pad(label, (0, max_len2 - len(label)), mode='constant', constant_values=processor.tokenizer.eos_token_id) for label in labels])\n",
    "    label_tensor = torch.tensor(padded_labels, dtype=torch.long)\n",
    "\n",
    "    return input_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T23:48:34.641535Z",
     "iopub.status.busy": "2025-03-23T23:48:34.641073Z",
     "iopub.status.idle": "2025-03-23T23:48:34.656240Z",
     "shell.execute_reply": "2025-03-23T23:48:34.655510Z",
     "shell.execute_reply.started": "2025-03-23T23:48:34.641507Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7d9b7140ee90>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke dataloader with parameters above\n",
    "train_loader = DataLoader(ds_train, batch_size=4, collate_fn=collate_fn)\n",
    "\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T23:48:34.657251Z",
     "iopub.status.busy": "2025-03-23T23:48:34.657032Z",
     "iopub.status.idle": "2025-03-23T23:48:34.671202Z",
     "shell.execute_reply": "2025-03-23T23:48:34.670189Z",
     "shell.execute_reply.started": "2025-03-23T23:48:34.657224Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STN1(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(1, 10), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(1, 10), stride=(1, 1))\n",
       "  (drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke speech-text first version model\n",
    "stn1 = STN1(vocab_size=len(processor.tokenizer)).to(device)\n",
    "\n",
    "stn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T23:48:34.672380Z",
     "iopub.status.busy": "2025-03-23T23:48:34.672007Z",
     "iopub.status.idle": "2025-03-23T23:48:34.682573Z",
     "shell.execute_reply": "2025-03-23T23:48:34.681730Z",
     "shell.execute_reply.started": "2025-03-23T23:48:34.672360Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.0001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " CTCLoss())"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training elements\n",
    "optimizer = optim.Adam(stn1.parameters(), lr=1e-4)\n",
    "criterion = nn.CTCLoss(blank=processor.tokenizer.pad_token_id)\n",
    "\n",
    "optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T23:48:34.683841Z",
     "iopub.status.busy": "2025-03-23T23:48:34.683541Z",
     "iopub.status.idle": "2025-03-23T23:48:34.694327Z",
     "shell.execute_reply": "2025-03-23T23:48:34.693706Z",
     "shell.execute_reply.started": "2025-03-23T23:48:34.683812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# load checkpoint elements, if exists\n",
    "checkpoint_pth = '/kaggle/working/checkpoint'\n",
    "epoch_pth = '/kaggle/working/epoch'\n",
    "\n",
    "start_epoch = 0\n",
    "if os.path.exists(checkpoint_pth):\n",
    "    stn1.load_state_dict(torch.load(checkpoint_pth))\n",
    "    with open(epoch_pth, 'r') as f:\n",
    "        start_epoch = int(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T23:48:34.695409Z",
     "iopub.status.busy": "2025-03-23T23:48:34.695182Z",
     "iopub.status.idle": "2025-03-23T23:48:49.881411Z",
     "shell.execute_reply": "2025-03-23T23:48:49.880213Z",
     "shell.execute_reply.started": "2025-03-23T23:48:34.695381Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 948736it [00:14, 64822.52it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4x2403480 and 320x50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-fb3b127a6eed>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# clean the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# add channel dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0minputs_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# new len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-221-c97b4daf12a9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x2403480 and 320x50)"
     ]
    }
   ],
   "source": [
    "# loop\n",
    "final_epoch = 5 # train all dataset for 5 times\n",
    "save_interval = 100 # save every 100 rows or batches\n",
    "\n",
    "for epoch in range(start_epoch, final_epoch):\n",
    "    stn1.train() # activate stn1 model training mode\n",
    "    total_loss = 0.0 # new training loss counting\n",
    "    \n",
    "    for idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad() # clean the gradient\n",
    "        \n",
    "        outputs = stn1(inputs.unsqueeze(1)) # add channel dimension\n",
    "        \n",
    "        inputs_lengths = torch.full((outputs.size(0), ), outputs.size(2), dtype=torch.long) # new len\n",
    "        target_lengths = torch.tensor([len(label) for label in labels], dytpe=torch.long) # new len\n",
    "\n",
    "        loss = criterion(outputs.permute(2, 0, 1), labels, inputs_lengths, target_lengths) # loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step() # update loss above\n",
    "        total_loss += loss.item() # add loss above\n",
    "        \n",
    "        if idx % save_interval == 0: # every save interval, save the checkpoint and epoch\n",
    "            print(f'Epoch {epoch+1} - Batch {idx+1}, Loss: {total_loss/save_interval:.4f}')\n",
    "            total_loss = 0.0\n",
    "\n",
    "            torch.save(stn1.state_dict(), checkpoint_pth)\n",
    "            with open(epoch_pth, 'w') as f:\n",
    "                f.write(str(epoch))\n",
    "            print('STN1 model checkpoint saved!')\n",
    "                        \n",
    "    print(f'Epoch {epoch} completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-23T23:48:49.881928Z",
     "iopub.status.idle": "2025-03-23T23:48:49.882182Z",
     "shell.execute_reply": "2025-03-23T23:48:49.882066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "stn1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-23T23:48:49.883275Z",
     "iopub.status.idle": "2025-03-23T23:48:49.883700Z",
     "shell.execute_reply": "2025-03-23T23:48:49.883509Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(stn1.state_dict(), 'kaggle/working/stn1_v1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-23T23:48:49.884808Z",
     "iopub.status.idle": "2025-03-23T23:48:49.885197Z",
     "shell.execute_reply": "2025-03-23T23:48:49.885027Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('STN1 training finished!')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
